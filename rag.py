from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from dotenv import load_dotenv
import os
load_dotenv()

CHROMA_PATH = "chromadb"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

#PROMPT_TEMPLATE = """
#Voc√™ √© um assistente jur√≠dico altamente especializado.  
#Responda estritamente com base no seguinte contexto extra√≠do dos documentos:  
#
#### **Contexto Fornecido:**  
#{context}  
#
#---
#
#Agora, responda √† seguinte pergunta de forma objetiva, clara e fundamentada:  
#
#**üîπ Pergunta:** {question}  
#
#### **Instru√ß√µes:**  
#1. **Baseie-se exclusivamente no contexto fornecido.**  
#2. **Se a resposta n√£o estiver no contexto, informe isso claramente.**  
#3. **Se houver m√∫ltiplos pontos relevantes, estruture a resposta em t√≥picos.**  
#4. **Identifique e destaque as leis, artigos ou regulamentos mencionados no contexto.**  
#5. **Use uma linguagem formal e precisa, como um parecer jur√≠dico.**  
#
#---
#
#### üìù **Resposta:**  
#
#**An√°lise Jur√≠dica:**  
#[Forne√ßa a resposta fundamentada com base no contexto.]  
#
#**Legisla√ß√£o Aplic√°vel:**  
#[Listar as leis, artigos ou regulamentos citados no contexto que sejam relevantes para a resposta.] 
#"""

#PROMPT_TEMPLATE = """" 
#Contexto: {context}  
#
#Tarefa: Voc√™ √© um especialista jur√≠dico em direito administrativo e constitucional. Sua miss√£o √© analisar a consulta do usu√°rio e responder com base exclusivamente nas informa√ß√µes fornecidas no contexto.  
#
#Passos:  
#1. **Classifica√ß√£o da Consulta:** Determine se a pergunta do usu√°rio se encaixa em uma das seguintes categorias:  
#   - **Fato**
#   - **Pedido**   
#   - **Argumento**
#
#2. **Resposta Estruturada:**  
#   - **Classifica√ß√£o da Query:** [Indicar se √© Fato, Pedido ou Argumento]  
#   - **An√°lise Jur√≠dica:** Explica√ß√£o da fundamenta√ß√£o legal aplic√°vel.  
#   - **Precedentes e Normas:** Cita√ß√£o de leis, jurisprud√™ncias ou princ√≠pios constitucionais relevantes.  
#   - **Conclus√£o:** Resumo da resposta de forma clara e objetiva.  
#
#Se n√£o houver informa√ß√µes suficientes no contexto para responder √† pergunta, diga explicitamente:  
#*"N√£o h√° informa√ß√µes suficientes no contexto para responder a esta pergunta."*
#"""

def prompt(description):
    PROMPT_TEMPLATE = f'''
        Contexto:  
        O documento fornecido est√° classificado sob o seguinte tema:  

        "{description}"   

        Classifica√ß√£o:  
        Classifique o documento em uma das seguintes categorias:  

        - **Fato** 
        - **Pedido**  
        - **Argumento**  

        Consulta:  
        "{{context}}"  

        Explica√ß√£o da Paragrafo:  
        Explique o paragrafo fornecida se relaciona com o tema do documento e por que √© relevante para a quest√£o jur√≠dica em discuss√£o.  
    '''
    return PROMPT_TEMPLATE

description = '''
A) POSSIBILIDADE DE REAJUSTE DE VENCIMENTO DAS CARREIRAS DO GRUPO DE ATIVIDADES DE EDUCA√á√ÉO B√ÅSICA DO PODER EXECUTIVO, PREVISTO PELO ARTIGO 3¬∫ DA LEI 21.710/2015 DO ESTADO DE MINAS GERAIS, COM BASE NAS ATUALIZA√á√ïES DO PISO SALARIAL NACIONAL DOS PROFISSIONAIS DA EDUCA√á√ÉO B√ÅSICA (LEI FEDERAL 11.738/2008); B) ABRANG√äNCIA DAS ALTERA√á√ïES EFETUADAS NO PROJETO DE REAJUSTE SALARIAL, PELA ASSEMBLEIA LEGISLATIVA E C) PERIODICIDADE A SER CONSIDERADA NAS ATUALIZA√á√ïES.

Descri√ß√£o:

Recurso extraordin√°rio em que se discute, √† luz dos artigos 1¬∫, 2¬∫, 18, 25, 37, X e XIII, 61, ¬ß 1¬∫, II, a e c, e 63, I, da Constitui√ß√£o Federal, a constitucionalidade do artigo 3¬∫ da Lei 21.710/2015 do Estado de Minas Gerais, que previu o reajuste de vencimento das carreiras do Grupo de Atividades de Educa√ß√£o B√°sica do Poder Executivo mediante lei espec√≠fica, observando-se as atualiza√ß√µes do piso salarial nacional dos profissionais da educa√ß√£o b√°sica (Lei federal 11.738/2008), bem como a abrang√™ncia das altera√ß√µes efetuadas pela Assembleia Legislativa no projeto encaminhado pelo Chefe do Poder Executivo, considerando-se a alega√ß√£o de aumento de despesa n√£o reconhecido na origem, e a defini√ß√£o de qual seria a periodicidade das atualiza√ß√µes a ser considerada.

Tese:

Assentada a constitucionalidade do piso salarial profissional nacional para os profissionais do magist√©rio p√∫blico da educa√ß√£o b√°sica e sua forma de atualiza√ß√£o, √© infraconstitucional, a ela se aplicando os efeitos da aus√™ncia de repercuss√£o geral, a controv√©rsia relativa aos reajustes de vencimento dos servidores do Grupo de Atividades de Educa√ß√£o B√°sica, com fundamento na Lei 21.710/2015 do Estado de Minas Gerais.
'''

query = '''
Cuida-se de a√ß√£o ordin√°ria por meio da qual a parte autora
pleiteia que seja o r√©u, ora recorrente, condenado a lhe pagar os valores de
reajuste do piso nacional da educa√ß√£o, referente aos meses de janeiro,
fevereiro e mar√ßo de 2016, tomando como base de c√°lculo o m√™s em que, de
fato, o reajuste foi concedido (abril de 2016), tudo com a corre√ß√£o monet√°ria
e juros devidos, pois afirma que, n√£o obstante a previs√£o expressa da Lei
Estadual 21.710/15, no sentido de que o servidor da educa√ß√£o deve ter
reajuste salarial em seu vencimento todo m√™s de janeiro, o r√©u atrasou o
cumprimento do disposto na norma supracitada  
'''

PROMPT_TEMPLATE = prompt(description)
print(PROMPT_TEMPLATE)

def query_rag(query_text, model_name: str):
    # chroma_dir = f"{CHROMA_PATH}_{model_name}"
    # chroma_dir = CHROMA_PATH
    embedding_function = OpenAIEmbeddings(model=model_name, openai_api_key=OPENAI_API_KEY)
    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)
    
    results = db.similarity_search_with_relevance_scores(query_text, k=5)

    print("\n\n Results:", results, "\n\n")
    print("\n\n Results:", results[0][1], "\n\n")
    
    if len(results) == 0 or results[0][1] < 0.75:
        return "Unable to find matching results."
    
    context_text = "\n\n - -\n\n".join([doc.page_content for doc, _ in results])
    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
    prompt = prompt_template.format(context=context_text, question=query_text)
    
    model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)
    response_text = model.predict(prompt)
    sources = [doc.metadata.get("source", None) for doc, _ in results]
    #print(sources)
    print("\n\n\n")
    
    formatted_response = f"Response: {response_text}\nSources: {sources}"
    return formatted_response, response_text
    return response_text


model_name = "text-embedding-ada-002"

formatted_response, response_text = query_rag(query, model_name)
print(formatted_response)
